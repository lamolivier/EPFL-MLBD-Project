{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec to embed the artists and the users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import hdbscan\n",
    "\n",
    "from helper_functions import load_pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>betty blowtorch</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>f2fb0ff0-5679-42ec-a55c-15109ce6e320</td>\n",
       "      <td>die Ärzte</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
       "      <td>melissa etheridge</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>3d6bbeb7-f90e-4d10-b440-e153c0d10b53</td>\n",
       "      <td>elvenking</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8</td>\n",
       "      <td>juliette &amp; the licks</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "3  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "4  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "\n",
       "                              artist_id           artist_name  plays  \n",
       "0  3bd73256-3905-4f3a-97e2-8b341527f805       betty blowtorch   2137  \n",
       "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320             die Ärzte   1099  \n",
       "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa     melissa etheridge    897  \n",
       "3  3d6bbeb7-f90e-4d10-b440-e153c0d10b53             elvenking    717  \n",
       "4  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8  juliette & the licks    706  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_consumption = ['user-mboxsha1', 'musicbrainz-artist-id', 'artist-name', 'plays']\n",
    "\n",
    "df = pd.read_csv('../data/usersha1-artmbid-artname-plays.tsv', sep='\\t', names=col_names_consumption)\n",
    "df = df.rename({'user-mboxsha1':'user_id', 'musicbrainz-artist-id':'artist_id', 'artist-name': 'artist_name'}, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-mboxsha1</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>signup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>f</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Feb 1, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001411dc427966b17297bf4d69e7e193135d89</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Dec 4, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004d2ac9316e22dc007ab2243d6fcb239e707d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Sep 1, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000063d3fe1cf2ba248b9e3c3f0334845a27a6bf</td>\n",
       "      <td>m</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Apr 28, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007a47085b9aab8af55f52ec8846ac479ac4fe</td>\n",
       "      <td>m</td>\n",
       "      <td>28.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Jan 27, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user-mboxsha1 gender   age        country  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b      f  22.0        Germany   \n",
       "1  00001411dc427966b17297bf4d69e7e193135d89      f   NaN         Canada   \n",
       "2  00004d2ac9316e22dc007ab2243d6fcb239e707d    NaN   NaN        Germany   \n",
       "3  000063d3fe1cf2ba248b9e3c3f0334845a27a6bf      m  19.0         Mexico   \n",
       "4  00007a47085b9aab8af55f52ec8846ac479ac4fe      m  28.0  United States   \n",
       "\n",
       "         signup  \n",
       "0   Feb 1, 2007  \n",
       "1   Dec 4, 2007  \n",
       "2   Sep 1, 2006  \n",
       "3  Apr 28, 2008  \n",
       "4  Jan 27, 2006  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names_user = ['user-mboxsha1', 'gender', 'age', 'country', 'signup']\n",
    "df_user = pd.read_csv('../data/usersha1-profile.tsv', sep='\\t', names=col_names_user)\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precomputed user-artist matrix\n",
    "user2id = load_pickle('../data/user2id.pickle')\n",
    "id2user = load_pickle('../data/id2user.pickle')\n",
    "artist2id = load_pickle('../data/artist2id.pickle')\n",
    "id2artist = load_pickle('../data/id2artist.pickle')\n",
    "\n",
    "matrix_plays = scipy.sparse.load_npz('../data/matrix_plays.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45076, 104897)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Densify the matrix\n",
    "dense_matrix_plays = matrix_plays.todense()\n",
    "dense_matrix_plays.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "\n",
    "def create_texts(matrix, dict_=id2artist, window_size=window_size):\n",
    "    \"\"\"Adapt the matrix to the format of word2vec, i.e., list of list of words (here artists or users)\"\"\"\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    for i in tqdm(range(len(matrix))):\n",
    "    \n",
    "        row = np.array(matrix[i])[0]\n",
    "        indices_non_zero = row.nonzero()[0]\n",
    "        values_non_zero = row[indices_non_zero]\n",
    "        values_non_zero = values_non_zero/values_non_zero.sum()\n",
    "\n",
    "        indices = np.random.choice(indices_non_zero, size=window_size, replace=True, p=values_non_zero)\n",
    "\n",
    "        texts.append([dict_.get(id_) for id_ in indices])\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## artist2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104897, 45076)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = dense_matrix_plays.T\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104897/104897 [03:49<00:00, 456.28it/s]\n"
     ]
    }
   ],
   "source": [
    "texts_artists = create_texts(matrix, id2artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Word2Vec model\n",
    "model = Word2Vec(sentences=texts_artists, window=window_size, workers=8)\n",
    "model.save(\"models/artist2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_most_similar(artist_name, k=10):\n",
    "    \"\"\"Print the k most similar artists based on the word2vec model.\"\"\"\n",
    "    \n",
    "    artist_id = artistid2artistname[artistid2artistname[\"artist_name\"] == artist_name].artist_id\n",
    "    \n",
    "    if len(artist_id) == 0:\n",
    "        print(\"No artist with the name {} found...\".format(artist_name))\n",
    "    else:\n",
    "        most_similar = model.wv.most_similar(artist_id, topn=k)\n",
    "        most_similar = np.array([list(ele) for ele in most_similar])\n",
    "        for artist_id in most_similar[:,0]:\n",
    "            print(list(artistid2artistname[artistid2artistname[\"artist_id\"] == artist_id].artist_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bill evans', 'bill evans.']\n",
      "['duke ellington']\n",
      "['chick corea']\n",
      "['dave brubeck quartet', 'davve brubeck quartet', 'the 1987 dave brubeck quartet', 'the dave brubeck quartet']\n",
      "['oascar peterson', 'oscar peterson']\n",
      "['basie count', 'cont basie', 'count basie']\n",
      "['stan getz']\n",
      "['sonny rollins']\n",
      "['montgomery wes', 'wes montgomery']\n",
      "['john scofield']\n"
     ]
    }
   ],
   "source": [
    "k_most_similar('keith jarrett')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alvin lee & ten years after', 'ten years after']\n",
      "['free']\n",
      "['rory gallagher']\n",
      "['buddy guy']\n",
      "['derek & the dominos', 'derek and the dominos']\n",
      "['cream']\n",
      "['johnny winter']\n",
      "['traffic']\n",
      "['sá, rodrix & guarabyra', 'sá, rodrix e guarabyra']\n",
      "[\"gov't mule\", 'govt mule', 'gov´t mule']\n"
     ]
    }
   ],
   "source": [
    "k_most_similar('jeff beck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50 cent']\n",
      "['snoog dogg', 'snoop', 'snoop dogg', 'snoop doggy dog', 'snoop doggy dogg', 'snoop doggy dogg featuring jd']\n",
      "['2 pac', '2pac', 'tupac', 'tupak shakur']\n",
      "['will smith']\n",
      "['petey pablo']\n",
      "['peter gelderblom']\n",
      "['ababy bash', 'baby bash']\n",
      "['run dmc', 'run-d.m.c.', 'run-dmc']\n",
      "['fort minor']\n",
      "['bruce faulconer']\n"
     ]
    }
   ],
   "source": [
    "k_most_similar('eminem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix containing all the vectors of artists\n",
    "artists_vectors = []\n",
    "artists_vectors_id = []\n",
    "for idx, artist in enumerate(model.wv.vocab):\n",
    "    artists_vectors.append(model.wv[artist])\n",
    "    artists_vectors_id.append(artist)\n",
    "\n",
    "artists_vectors = np.array(artists_vectors)\n",
    "artists_vectors_id = np.array(artists_vectors_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "artists_vectors_norm = (artists_vectors - artists_vectors.mean(axis=0))/artists_vectors.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the artists\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=15)\n",
    "clusterer.fit(artists_vectors_norm)\n",
    "hdbscan_labels = clusterer.labels_\n",
    "hdbscan_centers = clusterer.exemplars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    19346\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(hdbscan_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters obtained are not really convincing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45076, 104897)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Densify the matrix\n",
    "matrix = dense_matrix_plays.copy()\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45076/45076 [00:23<00:00, 1913.04it/s]\n"
     ]
    }
   ],
   "source": [
    "texts_users = create_texts(matrix, id2user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Word2Vec model\n",
    "model = Word2Vec(sentences=texts_users, window=30, workers=8)\n",
    "model.save(\"models/user2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_users(user_id, k=10):\n",
    "    \"\"\"Return a dataframe containing the demographic information on the most similar users of the user_id\"\"\"\n",
    "    \n",
    "    most_similar = model.wv.most_similar(user_id, topn=k)\n",
    "    most_similar = np.array([list(ele) for ele in most_similar])[:,0]\n",
    "    \n",
    "    df_similar_users = df_user[df_user['user-mboxsha1'].isin(most_similar)]\n",
    "    df_similar_users = df_similar_users[['gender','age','country']]\n",
    "    \n",
    "    return df_similar_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-mboxsha1</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>signup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0001a57568309b287363e72dc682e9a170ba6dc2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>May 12, 2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user-mboxsha1 gender   age        country  \\\n",
       "11  0001a57568309b287363e72dc682e9a170ba6dc2    NaN  23.0  United States   \n",
       "\n",
       "          signup  \n",
       "11  May 12, 2007  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "m    68\n",
       "f    25\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.0     1\n",
       "15.0     1\n",
       "17.0     2\n",
       "18.0     4\n",
       "19.0     5\n",
       "20.0     5\n",
       "21.0    13\n",
       "22.0     6\n",
       "23.0     4\n",
       "24.0     5\n",
       "25.0     8\n",
       "26.0     6\n",
       "27.0     3\n",
       "28.0     1\n",
       "29.0     3\n",
       "30.0     2\n",
       "31.0     2\n",
       "32.0     2\n",
       "33.0     1\n",
       "35.0     1\n",
       "36.0     1\n",
       "39.0     2\n",
       "41.0     1\n",
       "45.0     2\n",
       "47.0     1\n",
       "Name: age, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Australia                1\n",
       "Belarus                  1\n",
       "Belgium                  2\n",
       "Brazil                   4\n",
       "Bulgaria                 1\n",
       "Canada                   1\n",
       "Chile                    1\n",
       "Christmas Island         1\n",
       "Croatia                  2\n",
       "Czech Republic           4\n",
       "Estonia                  1\n",
       "Finland                  5\n",
       "France                   2\n",
       "Germany                 10\n",
       "Guatemala                1\n",
       "Ireland                  3\n",
       "Japan                    2\n",
       "Mexico                   1\n",
       "Myanmar                  1\n",
       "Netherlands              3\n",
       "Netherlands Antilles     1\n",
       "New Zealand              1\n",
       "Norway                   3\n",
       "Paraguay                 1\n",
       "Poland                   3\n",
       "Portugal                 1\n",
       "Russian Federation       8\n",
       "Serbia                   2\n",
       "Spain                    4\n",
       "Sweden                   2\n",
       "Switzerland              2\n",
       "Turkey                   3\n",
       "United Kingdom           7\n",
       "United States           15\n",
       "Name: country, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find similar users with similar demographic information\n",
    "user_id = list(user2id.keys())[4]\n",
    "display(df_user[df_user['user-mboxsha1'] == user_id])\n",
    "df_similar_users = most_similar_users(user_id, k=100)\n",
    "display(df_similar_users.gender.value_counts())\n",
    "print(\"\")\n",
    "display(df_similar_users.age.value_counts().sort_index())\n",
    "print(\"\")\n",
    "display(df_similar_users.country.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matrix containing all the vectors of users\n",
    "users_vectors = []\n",
    "user_vectors_id = []\n",
    "for idx, user in enumerate(model.wv.vocab):\n",
    "    users_vectors.append(model.wv[user])\n",
    "    user_vectors_id.append(user)\n",
    "\n",
    "users_vectors = np.array(users_vectors)\n",
    "user_vectors_id = np.array(user_vectors_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the users\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, min_samples=10)\n",
    "clusterer.fit(users_vectors)\n",
    "hdbscan_labels = clusterer.labels_\n",
    "hdbscan_centers = clusterer.exemplars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    36471\n",
       " 0      200\n",
       " 1       11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(hdbscan_labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters obtained are not really convincing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
